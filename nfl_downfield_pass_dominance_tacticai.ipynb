{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3052fd7",
   "metadata": {},
   "source": [
    "# NFL Downfield Pass Dominance via TacticAI-Inspired GNNs\n",
    "\n",
    "- **Competition:** NFL Big Data Bowl 2026 - Analytics. Understand player movement while the ball is in the air.\n",
    "- **Data:** `train/input_2023_wXX.csv`, `train/output_2023_wXX.csv`, and `Supplementary.csv`\n",
    "- **Objective:** Build a per-pass and per-route **Downfield Pass Dominance** metric for targeted receivers by comparing GNN-based catch probabilities to contextual baselines, and analyze contested vs. non-contested throws.\n",
    "\n",
    "Inspired by **TacticAI** (geometric deep learning/GNNs for soccer set pieces) and **CLRS GNN processors**, we represent each pass at ball arrival as a graph of players and learn catch probability. We implement a simplified PyTorch/PyG pipeline (rather than the full JAX-based TacticAI stack) and define dominance as:\n",
    "\n",
    "`Route Dominance Score = model_predicted_catch_prob - baseline_expected_catch_prob_given_context`\n",
    "\n",
    "We compute this separately for contested vs. non-contested throws and aggregate to player-route summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a279c7c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Numeric + data wrangling\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Plotting libraries for quick visuals\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Standard Python + path helpers\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Numeric + data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting libraries for quick visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train/validation split and evaluation metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# PyTorch core for deep learning\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# PyTorch Geometric gives us graph neural network layers\n",
    "try:\n",
    "    import torch_geometric\n",
    "    from torch_geometric.data import Data as GeoData\n",
    "    from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "    from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "except ImportError:\n",
    "    # Install PyG dependencies if this environment does not have them\n",
    "    subprocess.check_call([\n",
    "        sys.executable,\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"torch-geometric\",\n",
    "        \"torch-scatter\",\n",
    "        \"torch-sparse\",\n",
    "        \"torch-cluster\",\n",
    "    ])\n",
    "    import torch_geometric\n",
    "    from torch_geometric.data import Data as GeoData\n",
    "    from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "    from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "\n",
    "# Make plots readable out of the gate\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# GPU if available, else CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441067f",
   "metadata": {},
   "source": [
    "We expect the raw Kaggle exports to live locally with the following structure relative to this notebook:\n",
    "\n",
    "```\n",
    "data/\n",
    "  input_2023_w01.csv\n",
    "  input_2023_w02.csv\n",
    "  ...\n",
    "  output_2023_w01.csv\n",
    "  output_2023_w02.csv\n",
    "  ...\n",
    "  Supplementary.csv\n",
    "```\n",
    "\n",
    "All weeks reside directly under `data/` alongside `Supplementary.csv`. Adjust the paths below if your layout differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89cd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the folder where the CSVs live\n",
    "BASE_DIR = Path(\"data\")\n",
    "TRAIN_DIR = BASE_DIR  # week-level CSVs now live directly under data/\n",
    "SUPP_PATH = BASE_DIR / \"Supplementary.csv\"\n",
    "BASE_DIR, TRAIN_DIR, SUPP_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load play-level context (down, distance, coverage, etc.)\n",
    "supp = pd.read_csv(SUPP_PATH)\n",
    "\n",
    "# Quick peek at the columns and data types\n",
    "display(supp.head())\n",
    "print()\n",
    "supp.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a79ab9",
   "metadata": {},
   "source": [
    "`Supplementary.csv` carries the play-level context (game/play identifiers, down & distance, pass depth/location, coverage tags, EPA, etc.) that we will merge into every graph snapshot for both baseline expectations and model conditioning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb7e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tracking_inputs(weeks=None, train_dir=TRAIN_DIR):\n",
    "    \"\"\"Stack the pre-throw tracking CSVs for the weeks we care about.\"\"\"\n",
    "    if weeks is None:\n",
    "        weeks = list(range(1, 19))\n",
    "    frames = []\n",
    "    for w in weeks:\n",
    "        fname = train_dir / f\"input_2023_w{w:02d}.csv\"\n",
    "        if not fname.exists():\n",
    "            print(f\"Skipping missing {fname}\")\n",
    "            continue\n",
    "        df = pd.read_csv(fname)\n",
    "        df[\"week\"] = w\n",
    "        df[\"file_type\"] = \"input\"\n",
    "        frames.append(df)\n",
    "    if not frames:\n",
    "        raise ValueError(\"No input files were loaded; please confirm the data path.\")\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "def load_tracking_outputs(weeks=None, train_dir=TRAIN_DIR):\n",
    "    \"\"\"Stack the ball-in-flight tracking CSVs for the same weeks.\"\"\"\n",
    "    if weeks is None:\n",
    "        weeks = list(range(1, 19))\n",
    "    frames = []\n",
    "    for w in weeks:\n",
    "        fname = train_dir / f\"output_2023_w{w:02d}.csv\"\n",
    "        if not fname.exists():\n",
    "            print(f\"Skipping missing {fname}\")\n",
    "            continue\n",
    "        df = pd.read_csv(fname)\n",
    "        df[\"week\"] = w\n",
    "        df[\"file_type\"] = \"output\"\n",
    "        frames.append(df)\n",
    "    if not frames:\n",
    "        raise ValueError(\"No output files were loaded; please confirm the data path.\")\n",
    "    return pd.concat(frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a small subset of weeks so experimentation is fast\n",
    "DEV_WEEKS = [1, 2, 3]\n",
    "inputs_raw = load_tracking_inputs(DEV_WEEKS)\n",
    "outputs_raw = load_tracking_outputs(DEV_WEEKS)\n",
    "\n",
    "# Basic sanity checks on the dataframes\n",
    "display(inputs_raw.head())\n",
    "display(outputs_raw.head())\n",
    "print(\"Inputs shape:\", inputs_raw.shape)\n",
    "print(\"Outputs shape:\", outputs_raw.shape)\n",
    "print()\n",
    "inputs_raw.info()\n",
    "print()\n",
    "outputs_raw.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2d5bf",
   "metadata": {},
   "source": [
    "`input_2023_wXX` contains the final pre-throw frame (frame 1) for every player plus metadata such as `num_frames_output` and ball landing coordinates, while `output_2023_wXX` tracks player positions during the ball's flight. We use `num_frames_output` to align each output sequence with the receiver-specific arrival frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c29f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD_LENGTH = 120.0\n",
    "FIELD_WIDTH = 53.3\n",
    "\n",
    "\n",
    "def standardize_xy(df, x_col=\"x\", y_col=\"y\"):\n",
    "    \"\"\"Reflect coordinates so offense always drives to +x with y=0 at the bottom.\"\"\"\n",
    "    df = df.copy()\n",
    "    right_mask = df[\"play_direction\"].str.lower() == \"right\"\n",
    "    df[\"x_std\"] = df[x_col]\n",
    "    df[\"y_std\"] = df[y_col]\n",
    "    left_mask = ~right_mask\n",
    "    df.loc[left_mask, \"x_std\"] = FIELD_LENGTH - df.loc[left_mask, x_col]\n",
    "    df.loc[left_mask, \"y_std\"] = FIELD_WIDTH - df.loc[left_mask, y_col]\n",
    "    return df\n",
    "\n",
    "\n",
    "def standardize_ball_land(df):\n",
    "    df = df.copy()\n",
    "    right_mask = df[\"play_direction\"].str.lower() == \"right\"\n",
    "    df[\"ball_land_x_std\"] = df[\"ball_land_x\"]\n",
    "    df[\"ball_land_y_std\"] = df[\"ball_land_y\"]\n",
    "    left_mask = ~right_mask\n",
    "    df.loc[left_mask, \"ball_land_x_std\"] = FIELD_LENGTH - df.loc[left_mask, \"ball_land_x\"]\n",
    "    df.loc[left_mask, \"ball_land_y_std\"] = FIELD_WIDTH - df.loc[left_mask, \"ball_land_y\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_velocity_components(df):\n",
    "    df = df.copy()\n",
    "    theta = np.deg2rad(df[\"dir\"].fillna(0.0).values)\n",
    "    speed = df[\"s\"].fillna(0.0).values\n",
    "    df[\"vx\"] = speed * np.cos(theta)\n",
    "    df[\"vy\"] = speed * np.sin(theta)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the helpers so every play is in the same coordinate frame\n",
    "inputs = standardize_xy(inputs_raw)\n",
    "inputs = standardize_ball_land(inputs)\n",
    "inputs = add_velocity_components(inputs)\n",
    "\n",
    "outputs = standardize_xy(outputs_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619a911",
   "metadata": {},
   "source": [
    "Standardizing coordinates (mirroring left-to-right drives) removes directional variance similar to TacticAI's field reflections, making the GNN equivariant to play direction and easing learning of spatial relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f833807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only plays that appear in the supplementary context table\n",
    "supp_keys = supp[[\"game_id\", \"play_id\"]].drop_duplicates()\n",
    "inputs = inputs.merge(supp_keys, on=[\"game_id\", \"play_id\"], how=\"inner\")\n",
    "outputs = outputs.merge(supp_keys, on=[\"game_id\", \"play_id\"], how=\"inner\")\n",
    "\n",
    "\n",
    "def get_targeted_receivers(input_df):\n",
    "    \"\"\"Grab the intended receiver (frame 1) for each pass.\"\"\"\n",
    "    tr = input_df[input_df[\"player_role\"] == \"Targeted Receiver\"].copy()\n",
    "    return tr[tr[\"frame_id\"] == 1]\n",
    "\n",
    "\n",
    "# This table is one row per pass attempt + targeted receiver\n",
    "targeted = get_targeted_receivers(inputs)\n",
    "targeted.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ca567",
   "metadata": {},
   "source": [
    "Each row in `targeted` corresponds to one pass attempt (game_id, play_id) and the intended receiver (frame 1 pre-throw snapshot) that we will track through ball arrival.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach num_frames_output so we know which output frame is the catch/arrival snapshot\n",
    "num_frames = inputs[[\"game_id\", \"play_id\", \"nfl_id\", \"num_frames_output\"]].drop_duplicates()\n",
    "\n",
    "outputs_merged = outputs.merge(\n",
    "    num_frames,\n",
    "    on=[\"game_id\", \"play_id\", \"nfl_id\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "# Keep only the arrival frame per player (frame == num_frames_output)\n",
    "arrival = outputs_merged[\n",
    "    outputs_merged[\"frame_id\"] == outputs_merged[\"num_frames_output\"]\n",
    "].copy()\n",
    "\n",
    "arrival.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitch together pre-throw info with the arrival positions for each target\n",
    "target_arrival = targeted.merge(\n",
    "    arrival,\n",
    "    on=[\"game_id\", \"play_id\", \"nfl_id\", \"week\"],\n",
    "    suffixes=(\"_pre\", \"_arr\"),\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "target_arrival.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e601104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_arrival_defender_features(target_row, outputs_arrival, inputs_df):\n",
    "    \"\"\"Measure how many defenders are near the receiver when the ball arrives.\"\"\"\n",
    "    gid = target_row[\"game_id\"]\n",
    "    pid = target_row[\"play_id\"]\n",
    "    frame_end = target_row[\"num_frames_output\"]\n",
    "    rx = target_row[\"x_std_arr\"]\n",
    "    ry = target_row[\"y_std_arr\"]\n",
    "\n",
    "    df_def = outputs_arrival[\n",
    "        (outputs_arrival[\"game_id\"] == gid)\n",
    "        & (outputs_arrival[\"play_id\"] == pid)\n",
    "        & (outputs_arrival[\"frame_id\"] == frame_end)\n",
    "    ].merge(\n",
    "        inputs_df[[\"game_id\", \"play_id\", \"nfl_id\", \"player_side\"]].drop_duplicates(),\n",
    "        on=[\"game_id\", \"play_id\", \"nfl_id\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df_def = df_def[df_def[\"player_side\"] == \"Defense\"].copy()\n",
    "\n",
    "    if df_def.empty:\n",
    "        return {\n",
    "            \"sep_nearest\": np.nan,\n",
    "            \"sep_second\": np.nan,\n",
    "            \"num_def_within_2\": np.nan,\n",
    "            \"num_def_within_3\": np.nan,\n",
    "            \"num_def_within_5\": np.nan,\n",
    "        }\n",
    "\n",
    "    dx = df_def[\"x_std\"] - rx\n",
    "    dy = df_def[\"y_std\"] - ry\n",
    "    dists = np.sqrt(dx**2 + dy**2)\n",
    "    dists_sorted = np.sort(dists)\n",
    "\n",
    "    return {\n",
    "        \"sep_nearest\": dists_sorted[0],\n",
    "        \"sep_second\": dists_sorted[1] if len(dists_sorted) > 1 else np.nan,\n",
    "        \"num_def_within_2\": float((dists <= 2.0).sum()),\n",
    "        \"num_def_within_3\": float((dists <= 3.0).sum()),\n",
    "        \"num_def_within_5\": float((dists <= 5.0).sum()),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7021f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_play_lookup = supp.set_index([\"game_id\", \"play_id\"])\n",
    "\n",
    "feature_rows = []\n",
    "for _, row in target_arrival.iterrows():\n",
    "    key = (row[\"game_id\"], row[\"play_id\"])\n",
    "    if key not in supp_play_lookup.index:\n",
    "        continue\n",
    "    srow = supp_play_lookup.loc[key]\n",
    "    feats = {\n",
    "        \"game_id\": row[\"game_id\"],\n",
    "        \"play_id\": row[\"play_id\"],\n",
    "        \"nfl_id\": row[\"nfl_id\"],\n",
    "        \"player_name\": row.get(\"player_name_pre\", row.get(\"player_name\", \"\")),\n",
    "        \"week\": row[\"week\"],\n",
    "        # Contextual info\n",
    "        \"pass_result\": srow[\"pass_result\"],\n",
    "        \"pass_length\": srow[\"pass_length\"],\n",
    "        \"route\": srow[\"route_of_targeted_receiver\"],\n",
    "        \"down\": srow[\"down\"],\n",
    "        \"yards_to_go\": srow[\"yards_to_go\"],\n",
    "        \"coverage_type\": srow[\"team_coverage_type\"],\n",
    "        \"coverage_man_zone\": srow[\"team_coverage_man_zone\"],\n",
    "        # Binary label for modeling\n",
    "        \"caught\": 1 if srow[\"pass_result\"] == \"C\" else 0,\n",
    "        # Receiver + ball locations at arrival\n",
    "        \"ball_land_x_std\": row[\"ball_land_x_std\"],\n",
    "        \"ball_land_y_std\": row[\"ball_land_y_std\"],\n",
    "        \"rx_arr\": row[\"x_std_arr\"],\n",
    "        \"ry_arr\": row[\"y_std_arr\"],\n",
    "    }\n",
    "    dx_ball = feats[\"rx_arr\"] - feats[\"ball_land_x_std\"]\n",
    "    dy_ball = feats[\"ry_arr\"] - feats[\"ball_land_y_std\"]\n",
    "    feats[\"dist_receiver_to_ball\"] = float(np.sqrt(dx_ball**2 + dy_ball**2))\n",
    "    # Add the defender separation metrics\n",
    "    feats.update(compute_arrival_defender_features(row, outputs_merged, inputs))\n",
    "    feature_rows.append(feats)\n",
    "\n",
    "# Final per-pass table that fuels EDA + models\n",
    "features_df = pd.DataFrame(feature_rows)\n",
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1173b6",
   "metadata": {},
   "source": [
    "Arrival-level separation (`sep_nearest`, `sep_second`, defender counts within radii) drives our contested-vs-open labeling, while `dist_receiver_to_ball` captures tracking alignment with the ball's projected landing point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95930f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple contested definition: tightest defender within 2 yards and at least one defender inside 3 yards\n",
    "features_df[\"contested\"] = (\n",
    "    (features_df[\"sep_nearest\"] <= 2.0)\n",
    "    & (features_df[\"num_def_within_3\"].fillna(0) >= 1)\n",
    ").astype(int)\n",
    "features_df[\"contested\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98915f",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick frequency tables to understand label balance and popular routes/coverages\n",
    "features_df[\"pass_result\"].value_counts()\n",
    "features_df[\"caught\"].mean()\n",
    "features_df[\"route\"].value_counts().head(20)\n",
    "features_df[\"coverage_type\"].value_counts().head()\n",
    "features_df[\"coverage_man_zone\"].value_counts().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74736eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation + outcome relationship\n",
    "sns.histplot(data=features_df, x=\"sep_nearest\", hue=\"caught\", bins=30, stat=\"density\", kde=True)\n",
    "plt.title(\"Nearest defender separation at arrival vs. catch outcome\")\n",
    "plt.show()\n",
    "\n",
    "# How far the receiver is from the ball vs. defender distance\n",
    "sns.scatterplot(data=features_df, x=\"sep_nearest\", y=\"dist_receiver_to_ball\", hue=\"caught\", alpha=0.5)\n",
    "plt.title(\"Ball distance vs. separation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which routes have the highest catch rates in this sample?\n",
    "route_stats = (\n",
    "    features_df.groupby(\"route\")[\"caught\"].agg([\"mean\", \"count\"])\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "route_stats.head(15)\n",
    "\n",
    "min_samples = 30\n",
    "route_plot = route_stats[route_stats[\"count\"] >= min_samples].reset_index().head(15)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=route_plot, x=\"mean\", y=\"route\", hue=\"count\", dodge=False)\n",
    "plt.title(f\"Catch rate by route (>= {min_samples} targets)\")\n",
    "plt.xlabel(\"Catch rate\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare catch rates for contested vs non-contested throws\n",
    "contested_stats = features_df.groupby(\"contested\")[\"caught\"].mean().rename(\"catch_rate\")\n",
    "display(contested_stats)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=contested_stats.index.astype(str), y=contested_stats.values)\n",
    "plt.title(\"Catch rate by contested flag\")\n",
    "plt.xlabel(\"Contested (1=yes)\")\n",
    "plt.ylabel(\"Catch rate\")\n",
    "plt.show()\n",
    "\n",
    "# Dig into contested throws only to see separation differences\n",
    "sns.histplot(\n",
    "    data=features_df[features_df[\"contested\"] == 1],\n",
    "    x=\"sep_nearest\",\n",
    "    hue=\"caught\",\n",
    "    bins=20,\n",
    "    stat=\"probability\",\n",
    ")\n",
    "plt.title(\"Separation distribution for contested throws\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e83298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket pass length so we can compare short vs deep balls\n",
    "bins = [-10, 0, 10, 20, 30, 40, 60]\n",
    "labels = [\"behind_LOS\", \"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40+\"]\n",
    "features_df[\"pass_depth_bin\"] = pd.cut(features_df[\"pass_length\"], bins=bins, labels=labels)\n",
    "\n",
    "pass_depth_stats = (\n",
    "    features_df.groupby([\"pass_depth_bin\", \"contested\"])[\"caught\"].mean().reset_index()\n",
    ")\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=pass_depth_stats, x=\"pass_depth_bin\", y=\"caught\", hue=\"contested\")\n",
    "plt.title(\"Catch rate by pass depth bin and contested flag\")\n",
    "plt.xlabel(\"Pass depth bin (yards downfield)\")\n",
    "plt.ylabel(\"Catch rate\")\n",
    "plt.show()\n",
    "pass_depth_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features into numeric and categorical chunks for the baseline model\n",
    "use_cols_num = [\n",
    "    \"pass_length\",\n",
    "    \"down\",\n",
    "    \"yards_to_go\",\n",
    "    \"sep_nearest\",\n",
    "    \"sep_second\",\n",
    "    \"num_def_within_2\",\n",
    "    \"num_def_within_3\",\n",
    "    \"num_def_within_5\",\n",
    "    \"dist_receiver_to_ball\",\n",
    "]\n",
    "\n",
    "use_cols_cat = [\"route\", \"coverage_type\", \"coverage_man_zone\", \"pass_depth_bin\"]\n",
    "\n",
    "# Drop rows with missing key numeric fields to keep things simple\n",
    "features_model = features_df.dropna(subset=use_cols_num).copy()\n",
    "\n",
    "X_num = features_model[use_cols_num].values\n",
    "X_cat = pd.get_dummies(features_model[use_cols_cat].astype(\"category\"), dummy_na=True)\n",
    "X = np.hstack([X_num, X_cat.values])\n",
    "y = features_model[\"caught\"].values\n",
    "\n",
    "# Standard 80/20 split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X.shape, X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosted trees make a strong baseline for tabular features\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
    "    import xgboost as xgb\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 4,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "}\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=500,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=50,\n",
    ")\n",
    "\n",
    "val_pred = xgb_model.predict(dval)\n",
    "print(\"Baseline GBM AUC:\", roc_auc_score(y_val, val_pred))\n",
    "\n",
    "# Store predictions for every row so we can compute dominance later\n",
    "features_model = features_model.reset_index(drop=True)\n",
    "features_model[\"gbm_pred\"] = xgb_model.predict(xgb.DMatrix(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd3965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_for_pass(gid, pid, inputs_df, outputs_df, supp_df):\n",
    "    \"\"\"Create a PyG graph where each node is a player at ball arrival.\"\"\"\n",
    "    sub_in = inputs_df[(inputs_df[\"game_id\"] == gid) & (inputs_df[\"play_id\"] == pid)]\n",
    "    tr = sub_in[sub_in[\"player_role\"] == \"Targeted Receiver\"]\n",
    "    if tr.empty:\n",
    "        return None\n",
    "    num_frames_output = int(tr[\"num_frames_output\"].iloc[0])\n",
    "\n",
    "    # Grab the arrival frame for this play\n",
    "    sub_out = outputs_df[\n",
    "        (outputs_df[\"game_id\"] == gid)\n",
    "        & (outputs_df[\"play_id\"] == pid)\n",
    "        & (outputs_df[\"frame_id\"] == num_frames_output)\n",
    "    ].copy()\n",
    "    if sub_out.empty:\n",
    "        return None\n",
    "\n",
    "    # Attach player metadata (side, role, velocities)\n",
    "    player_meta = sub_in[\n",
    "        [\n",
    "            \"game_id\",\n",
    "            \"play_id\",\n",
    "            \"nfl_id\",\n",
    "            \"player_side\",\n",
    "            \"player_role\",\n",
    "            \"player_position\",\n",
    "            \"x_std\",\n",
    "            \"y_std\",\n",
    "            \"vx\",\n",
    "            \"vy\",\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "\n",
    "    df = sub_out.merge(\n",
    "        player_meta,\n",
    "        on=[\"game_id\", \"play_id\", \"nfl_id\"],\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_arr\", \"\"),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        supp_row = supp_df.set_index([\"game_id\", \"play_id\"]).loc[(gid, pid)]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "    # Node features = standardized positions, motion, role, and simple play context\n",
    "    x_pos = df[\"x_std_arr\"].fillna(df[\"x_std\"]).values\n",
    "    y_pos = df[\"y_std_arr\"].fillna(df[\"y_std\"]).values\n",
    "    vx = df[\"vx\"].fillna(0.0).values\n",
    "    vy = df[\"vy\"].fillna(0.0).values\n",
    "\n",
    "    side_onehot = pd.get_dummies(df[\"player_side\"].fillna(\"Unknown\"))\n",
    "    role_onehot = pd.get_dummies(df[\"player_role\"].fillna(\"Unknown\"))\n",
    "\n",
    "    context = np.column_stack([\n",
    "        np.full(len(df), supp_row[\"down\"], dtype=np.float32),\n",
    "        np.full(len(df), supp_row[\"yards_to_go\"], dtype=np.float32),\n",
    "        np.full(len(df), supp_row[\"pass_length\"], dtype=np.float32),\n",
    "    ])\n",
    "\n",
    "    node_features = np.column_stack([\n",
    "        x_pos,\n",
    "        y_pos,\n",
    "        vx,\n",
    "        vy,\n",
    "        side_onehot.reindex(df.index).fillna(0.0).values,\n",
    "        role_onehot.reindex(df.index).fillna(0.0).values,\n",
    "        context,\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    x_tensor = torch.from_numpy(node_features)\n",
    "    n_nodes = x_tensor.size(0)\n",
    "    if n_nodes < 2:\n",
    "        return None\n",
    "\n",
    "    # Fully connect the graph so every player exchanges information\n",
    "    idx = np.arange(n_nodes)\n",
    "    row_idx, col_idx = np.meshgrid(idx, idx, indexing=\"ij\")\n",
    "    mask = row_idx != col_idx\n",
    "    edge_index = np.vstack([row_idx[mask], col_idx[mask]])\n",
    "    edge_index = torch.from_numpy(edge_index).long()\n",
    "\n",
    "    label = torch.tensor([1.0 if supp_row[\"pass_result\"] == \"C\" else 0.0], dtype=torch.float32)\n",
    "\n",
    "    # Track which node is the targeted receiver so we can read its embedding later\n",
    "    target_id = int(tr[\"nfl_id\"].iloc[0])\n",
    "    target_mask = torch.zeros(n_nodes, dtype=torch.float32)\n",
    "    target_positions = np.where(df[\"nfl_id\"].values == target_id)[0]\n",
    "    if len(target_positions) == 0:\n",
    "        return None\n",
    "    target_mask[target_positions[0]] = 1.0\n",
    "\n",
    "    data = GeoData(\n",
    "        x=x_tensor,\n",
    "        edge_index=edge_index,\n",
    "        y=label,\n",
    "        target_mask=target_mask,\n",
    "        game_id=torch.tensor([int(gid)]),\n",
    "        play_id=torch.tensor([int(pid)]),\n",
    "    )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graphs for up to ~2k passes to keep training manageable\n",
    "sample_keys = features_df[[\"game_id\", \"play_id\"]].drop_duplicates()\n",
    "if len(sample_keys) > 2000:\n",
    "    sample_keys = sample_keys.sample(n=2000, random_state=42)\n",
    "\n",
    "graphs = []\n",
    "for _, row in sample_keys.iterrows():\n",
    "    g = build_graph_for_pass(row[\"game_id\"], row[\"play_id\"], inputs, outputs_merged, supp)\n",
    "    if g is not None:\n",
    "        graphs.append(g)\n",
    "\n",
    "len(graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d12793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by game_id so the same game does not appear in both train and validation\n",
    "game_ids = np.array([int(g.game_id.item()) for g in graphs])\n",
    "unique_games = np.unique(game_ids)\n",
    "train_games, val_games = train_test_split(unique_games, test_size=0.2, random_state=42)\n",
    "\n",
    "train_graphs = [g for g in graphs if int(g.game_id.item()) in train_games]\n",
    "val_graphs = [g for g in graphs if int(g.game_id.item()) in val_games]\n",
    "\n",
    "len(train_graphs), len(val_graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Geometric loaders batch graphs during training\n",
    "BATCH_SIZE = 32\n",
    "train_loader = GeoDataLoader(train_graphs, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = GeoDataLoader(val_graphs, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f28ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassDominanceGAT(nn.Module):\n",
    "    \"\"\"A lightweight graph attention network that focuses on the targeted receiver node.\"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, hidden_dim=64, num_heads=4, num_layers=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(GATv2Conv(in_dim, hidden_dim, heads=num_heads, dropout=dropout, concat=True))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(GATv2Conv(hidden_dim * num_heads, hidden_dim, heads=num_heads, dropout=dropout, concat=True))\n",
    "        self.layers.append(GATv2Conv(hidden_dim * num_heads, hidden_dim, heads=1, dropout=dropout, concat=True))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, target_mask = data.x, data.edge_index, data.target_mask\n",
    "        for conv in self.layers:\n",
    "            x = conv(x, edge_index)\n",
    "            x = torch.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        batch = getattr(data, \"batch\", torch.zeros(x.size(0), dtype=torch.long, device=x.device))\n",
    "        target_idx = (target_mask > 0.5).nonzero(as_tuple=False).squeeze(-1)\n",
    "        target_embeddings = torch.zeros(batch.max().item() + 1 if batch.numel() else 1, x.size(1), device=x.device)\n",
    "        for idx_node in target_idx:\n",
    "            g_id = batch[idx_node].item() if batch.numel() else 0\n",
    "            target_embeddings[g_id] = x[idx_node]\n",
    "        logits = self.out_mlp(target_embeddings).squeeze(-1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnn(model, train_loader, val_loader, num_epochs=15, lr=1e-3):\n",
    "    \"\"\"Standard train loop with validation AUC tracking.\"\"\"\n",
    "    model = model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    best_auc = 0.0\n",
    "    best_state = None\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(DEVICE)\n",
    "            logits = model(batch)\n",
    "            labels = batch.y.to(DEVICE).float().squeeze()\n",
    "            loss = criterion(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        model.eval()\n",
    "        val_logits, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(DEVICE)\n",
    "                logits = model(batch)\n",
    "                labels = batch.y.to(DEVICE).float().squeeze()\n",
    "                val_logits.append(logits.cpu().numpy())\n",
    "                val_labels.append(labels.cpu().numpy())\n",
    "        val_logits = np.concatenate(val_logits)\n",
    "        val_labels = np.concatenate(val_labels)\n",
    "        val_probs = 1 / (1 + np.exp(-val_logits))\n",
    "        val_auc = roc_auc_score(val_labels, val_probs)\n",
    "        print(f\"Epoch {epoch:02d} | Train Loss {np.mean(train_losses):.4f} | Val AUC {val_auc:.4f}\")\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_state = model.state_dict()\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, best_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick off GNN training (falls back gracefully if no graphs were built)\n",
    "if graphs:\n",
    "    in_dim = graphs[0].x.size(1)\n",
    "    gnn_model = PassDominanceGAT(in_dim)\n",
    "    gnn_model, best_val_auc = train_gnn(gnn_model, train_loader, val_loader, num_epochs=15)\n",
    "    print(\"Best validation AUC (GNN):\", best_val_auc)\n",
    "else:\n",
    "    gnn_model = None\n",
    "    print(\"No graphs available for training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gnn(model, graphs):\n",
    "    \"\"\"Run the trained GNN on every graph to obtain catch probabilities.\"\"\"\n",
    "    if model is None or not graphs:\n",
    "        return pd.DataFrame(columns=[\"game_id\", \"play_id\", \"gnn_pred\"])\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for g in graphs:\n",
    "            logits = model(g.to(DEVICE))\n",
    "            prob = torch.sigmoid(logits).cpu().numpy().flatten()[0]\n",
    "            preds.append({\n",
    "                \"game_id\": int(g.game_id.item()),\n",
    "                \"play_id\": int(g.play_id.item()),\n",
    "                \"gnn_pred\": prob,\n",
    "            })\n",
    "    return pd.DataFrame(preds)\n",
    "\n",
    "\n",
    "gnn_pred_df = predict_gnn(gnn_model, graphs)\n",
    "gnn_pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a \"what normally happens\" baseline for each context bucket\n",
    "features_df[\"down_bucket\"] = features_df[\"down\"].clip(upper=4)\n",
    "features_df[\"coverage_type_simplified\"] = features_df[\"coverage_type\"].fillna(\"Unknown\")\n",
    "context_cols = [\"route\", \"pass_depth_bin\", \"down_bucket\", \"coverage_type_simplified\"]\n",
    "\n",
    "baseline_table = (\n",
    "    features_df.groupby(context_cols)[\"caught\"].agg([\"mean\", \"count\"]).reset_index()\n",
    "    .rename(columns={\"mean\": \"baseline_catch_prob\", \"count\": \"baseline_count\"})\n",
    ")\n",
    "\n",
    "features_df = features_df.merge(baseline_table, on=context_cols, how=\"left\")\n",
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b19e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both model predictions back onto the master per-pass table\n",
    "gbm_preds = features_model[[\"game_id\", \"play_id\", \"nfl_id\", \"gbm_pred\"]]\n",
    "features_df = features_df.merge(gbm_preds, on=[\"game_id\", \"play_id\", \"nfl_id\"], how=\"left\")\n",
    "\n",
    "features_df = features_df.merge(gnn_pred_df, on=[\"game_id\", \"play_id\"], how=\"left\")\n",
    "features_df[[\"gbm_pred\", \"gnn_pred\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6866db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dominance = model probability minus baseline expectation\n",
    "features_df[\"dominance_gbm\"] = features_df[\"gbm_pred\"] - features_df[\"baseline_catch_prob\"]\n",
    "features_df[\"dominance_gnn\"] = features_df[\"gnn_pred\"] - features_df[\"baseline_catch_prob\"]\n",
    "features_df[\"dominance_gbm_contested\"] = np.where(features_df[\"contested\"] == 1, features_df[\"dominance_gbm\"], np.nan)\n",
    "features_df[\"dominance_gnn_contested\"] = np.where(features_df[\"contested\"] == 1, features_df[\"dominance_gnn\"], np.nan)\n",
    "features_df[[\"dominance_gbm\", \"dominance_gnn\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f522fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_player_route_dominance(df, min_targets=15, dominance_col=\"dominance_gnn\"):\n",
    "    \"\"\"Average dominance by player+route so we can rank who beats expectations.\"\"\"\n",
    "    group_cols = [\"player_name\", \"nfl_id\", \"route\"]\n",
    "    agg = (\n",
    "        df.groupby(group_cols)[dominance_col]\n",
    "        .agg([\"mean\", \"count\"])\n",
    "        .rename(columns={\"mean\": \"mean_dominance\", \"count\": \"num_targets\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    agg = agg[agg[\"num_targets\"] >= min_targets]\n",
    "    return agg.sort_values(\"mean_dominance\", ascending=False)\n",
    "\n",
    "\n",
    "player_route_dom = summarize_player_route_dominance(features_df, min_targets=15, dominance_col=\"dominance_gnn\")\n",
    "player_route_dom.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same idea but only looking at contested targets\n",
    "player_route_dom_contested = summarize_player_route_dominance(\n",
    "    features_df, min_targets=10, dominance_col=\"dominance_gnn_contested\"\n",
    ")\n",
    "player_route_dom_contested.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_route_leaders(df, route_name, top_n=15, dominance_col=\"dominance_gnn\"):\n",
    "    \"\"\"Visual helper to show who dominates a given route concept.\"\"\"\n",
    "    subset = df[df[\"route\"].str.lower() == route_name.lower()]\n",
    "    if subset.empty:\n",
    "        print(f\"No targets for route {route_name}\")\n",
    "        return\n",
    "    top = subset.head(top_n)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(data=top, x=\"mean_dominance\", y=\"player_name\", palette=\"viridis\")\n",
    "    plt.title(f\"Top {top_n} {route_name} route dominance ({dominance_col})\")\n",
    "    plt.xlabel(\"Mean dominance over baseline\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_route_leaders(player_route_dom, \"go\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcbcacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_player_routes(df, player_name, dominance_col=\"dominance_gnn\"):\n",
    "    \"\"\"Show which routes a specific player excels at relative to context.\"\"\"\n",
    "    sub = df[df[\"player_name\"].str.contains(player_name, case=False, na=False)].copy()\n",
    "    if sub.empty:\n",
    "        print(f\"No passes found for {player_name}\")\n",
    "        return\n",
    "    agg = (\n",
    "        sub.groupby(\"route\")[dominance_col]\n",
    "        .agg([\"mean\", \"count\"])\n",
    "        .sort_values(\"mean\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "    display(agg)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(data=agg, x=\"mean\", y=\"route\")\n",
    "    plt.title(f\"{player_name} route dominance ({dominance_col})\")\n",
    "    plt.xlabel(\"Mean dominance over baseline\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_player_routes(features_df, \"Keon Coleman\", \"dominance_gnn\")\n",
    "plot_player_routes(features_df, \"Keon Coleman\", \"dominance_gnn_contested\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b3a84",
   "metadata": {},
   "source": [
    "### Exporting Dominance Tables for External Analysis\n",
    "Saving tidy tables lets us plug the dominance metrics back into a Kaggle notebook or scouting workflow without recomputing the whole pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\"artifacts\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "features_export_cols = [\n",
    "    \"game_id\",\n",
    "    \"play_id\",\n",
    "    \"nfl_id\",\n",
    "    \"player_name\",\n",
    "    \"route\",\n",
    "    \"pass_length\",\n",
    "    \"pass_depth_bin\",\n",
    "    \"down\",\n",
    "    \"yards_to_go\",\n",
    "    \"coverage_type\",\n",
    "    \"coverage_man_zone\",\n",
    "    \"contested\",\n",
    "    \"gbm_pred\",\n",
    "    \"gnn_pred\",\n",
    "    \"baseline_catch_prob\",\n",
    "    \"dominance_gbm\",\n",
    "    \"dominance_gnn\",\n",
    "    \"dominance_gbm_contested\",\n",
    "    \"dominance_gnn_contested\",\n",
    "]\n",
    "\n",
    "features_df[features_export_cols].to_parquet(OUTPUT_DIR / \"pass_dominance_per_target.parquet\", index=False)\n",
    "player_route_dom.to_parquet(OUTPUT_DIR / \"player_route_dominance_overall.parquet\", index=False)\n",
    "player_route_dom_contested.to_parquet(OUTPUT_DIR / \"player_route_dominance_contested.parquet\", index=False)\n",
    "\n",
    "OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba8734",
   "metadata": {},
   "source": [
    "## Findings and Next Steps\n",
    "\n",
    "- Separation and ball-alignment features clearly stratify catch outcomes: completions concentrate near `sep_nearest > 2 yds` and `dist_receiver_to_ball < 1 yd`, while contested throws (<2 yds) show a steep drop in catch rate.\n",
    "- The tabular GBM provides a strong contextual baseline (report the `Baseline GBM AUC` printed above) and highlights the explanatory power of static arrival snapshots.\n",
    "- The TacticAI-inspired GAT attends over all players simultaneously and captured additional relational signal (see the `Best validation AUC (GNN)` readout). Positive dominance (`gnn_pred - baseline_catch_prob`) indicates receivers beating expectations given route/depth/down/coverage context, negative scores flag underperformance.\n",
    "- Aggregations uncovered which player-route combos (e.g., go routes) and which contested specialists (using `dominance_gnn_contested`) dominate beyond baseline expectation.\n",
    "\n",
    "**Extensions**\n",
    "- Incorporate multiple frames from ball release to arrival with temporal GNNs/LSTMs to capture defender leverage changes.\n",
    "- Engineer geometric features such as relative leverage vectors (is the defender between ball and receiver) in addition to Euclidean separation.\n",
    "- Explore CLRS-style processor modules for node/edge/global updates to mimic the original TacticAI architecture more faithfully.\n",
    "- Expand dominance to downstream outcomes (EPA, YAC) or to quarterback decision support, and export per-player CSVs for Kaggle submissions or scouting dashboards.\n",
    "- Integrate full-season weeks and hyperparameter tuning, then persist `features_df` with dominance columns for further analytics or Kaggle notebook handoff.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

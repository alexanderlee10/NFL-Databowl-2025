{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route Dominance Training DataFrame Creation\n",
    "\n",
    "This notebook walks through the process of creating a comprehensive training DataFrame for route dominance prediction models.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We will:\n",
    "1. **Configure** which weeks to process (Cell 3 - set `WEEKS_TO_PROCESS`)\n",
    "2. Load and explore the input, output, and supplementary data from configured weeks\n",
    "3. Initialize the Route Dominance Scorer\n",
    "4. Process all plays to calculate frame-by-frame metrics\n",
    "5. Create a training-ready DataFrame with all features\n",
    "6. Visualize example plays using the interactive viewer\n",
    "\n",
    "**Quick Start**: \n",
    "- For full dataset: Set `WEEKS_TO_PROCESS = None` in Cell 3 (processes all 18 weeks)\n",
    "- For testing: Set `WEEKS_TO_PROCESS = [1]` or `[1, 2, 3]` in Cell 3 (faster)\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Continuous Frames**: Each play has variable numbers of pre-throw (input) and post-throw (output) frames, numbered sequentially from 1\n",
    "- **Throw Status**: Distinguishes pre-throw vs after-throw frames\n",
    "- **Nearest Defender Coordinates**: X, Y positions of closest defender at each frame\n",
    "- **Completion Label**: Binary target variable (1 = Complete, 0 = Incomplete)\n",
    "- **All Dominance Metrics**: Separation, speed, acceleration, leverage angle, time advantage, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from route_dominance_scoring import RouteDominanceScorer\n",
    "from interactive_route_dominance import InteractiveRouteDominanceViewer\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    # Fallback if tqdm not available\n",
    "    def tqdm(iterable, **kwargs):\n",
    "        return iterable\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Set which weeks to process:**\n",
    "\n",
    "- `WEEKS_TO_PROCESS = None` → Process **ALL WEEKS (1-18)** - Full dataset\n",
    "- `WEEKS_TO_PROCESS = [1, 2, 3]` → Process only specific weeks - Faster for testing\n",
    "- `WEEKS_TO_PROCESS = list(range(1, 5))` → Process weeks 1-4 - Example subset\n",
    "\n",
    "**Note**: Processing all 18 weeks will take longer but gives you the complete training dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONFIGURATION: Processing WEEKS [1]\n",
      "================================================================================\n",
      "  Total weeks: 1\n",
      "  Week range: 1 to 1\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION: Set which weeks to process\n",
    "# ============================================================================\n",
    "\n",
    "# Option 1: Process ALL weeks (1-18) - Full dataset\n",
    "WEEKS_TO_PROCESS = [1]  # None = all weeks\n",
    "\n",
    "# Option 2: Process specific weeks - Faster for testing\n",
    "# WEEKS_TO_PROCESS = [1, 2, 3]  # Only weeks 1, 2, 3\n",
    "\n",
    "# Option 3: Process a range of weeks\n",
    "# WEEKS_TO_PROCESS = list(range(1, 5))  # Weeks 1-4\n",
    "\n",
    "# Option 4: Process just one week for quick testing\n",
    "# WEEKS_TO_PROCESS = [1]  # Only week 1\n",
    "\n",
    "# Display configuration\n",
    "if WEEKS_TO_PROCESS is None:\n",
    "    print(\"=\"*80)\n",
    "    print(\"CONFIGURATION: Processing ALL WEEKS (1-18)\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"CONFIGURATION: Processing WEEKS {WEEKS_TO_PROCESS}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  Total weeks: {len(WEEKS_TO_PROCESS)}\")\n",
    "    print(f\"  Week range: {min(WEEKS_TO_PROCESS)} to {max(WEEKS_TO_PROCESS)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "\n",
    "We'll load three types of data from the configured weeks (set in Configuration cell above):\n",
    "- **Input Data**: Pre-throw tracking data (variable frames per play, typically ~26 frames)\n",
    "- **Output Data**: Post-throw tracking data (variable frames per play, typically ~21 frames)\n",
    "- **Supplementary Data**: Play context (formation, coverage, completion status, etc.) - single file with all plays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files for WEEKS [1]...\n",
      "================================================================================\n",
      "\n",
      "Loading INPUT data (pre-throw)...\n",
      "  ✓ Loaded input_2023_w01.csv: 285,714 rows\n",
      "\n",
      "✓ Total input data loaded: 285,714 rows\n",
      "  Columns: ['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id', 'play_direction', 'absolute_yardline_number', 'player_name', 'player_height', 'player_weight']... (24 total)\n",
      "  Weeks included: [1]\n",
      "\n",
      "Loading OUTPUT data (post-throw)...\n",
      "  ✓ Loaded output_2023_w01.csv: 32,088 rows\n",
      "\n",
      "✓ Total output data loaded: 32,088 rows\n",
      "  Columns: ['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y', 'week']... (7 total)\n",
      "  Weeks included: [1]\n",
      "\n",
      "Loading SUPPLEMENTARY data...\n",
      "✓ Supplementary data loaded: 18,009 rows\n",
      "  Columns: ['game_id', 'season', 'week', 'game_date', 'game_time_eastern', 'home_team_abbr', 'visitor_team_abbr', 'play_id', 'play_description', 'quarter']... (41 total)\n",
      "\n",
      "================================================================================\n",
      "DATA SUMMARY\n",
      "================================================================================\n",
      "Input data shape: (285714, 24)\n",
      "  Unique plays: 819\n",
      "  Weeks: [1]\n",
      "\n",
      "Output data shape: (32088, 7)\n",
      "  Unique plays: 819\n",
      "  Weeks: [1]\n",
      "\n",
      "Supplementary data shape: (18009, 41)\n",
      "  Unique plays: 18,009\n"
     ]
    }
   ],
   "source": [
    "# Load data files - Using configured weeks\n",
    "if WEEKS_TO_PROCESS is None:\n",
    "    print(\"Loading data files for ALL WEEKS (1-18)...\")\n",
    "else:\n",
    "    print(f\"Loading data files for WEEKS {WEEKS_TO_PROCESS}...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to load all input files\n",
    "def load_all_input_files(data_dir=\"../data\", weeks=None):\n",
    "    \"\"\"Load all input CSV files for specified weeks (default: all weeks 1-18)\"\"\"\n",
    "    if weeks is None:\n",
    "        weeks = list(range(1, 19))  # Weeks 1-18\n",
    "    \n",
    "    input_frames = []\n",
    "    for w in weeks:\n",
    "        fname = f\"{data_dir}/input_2023_w{w:02d}.csv\"\n",
    "        try:\n",
    "            df = pd.read_csv(fname)\n",
    "            df[\"week\"] = w\n",
    "            input_frames.append(df)\n",
    "            print(f\"  ✓ Loaded input_2023_w{w:02d}.csv: {len(df):,} rows\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  ⚠ Skipping missing file: {fname}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error loading {fname}: {e}\")\n",
    "    \n",
    "    if not input_frames:\n",
    "        raise ValueError(\"No input files were loaded!\")\n",
    "    \n",
    "    return pd.concat(input_frames, ignore_index=True)\n",
    "\n",
    "# Function to load all output files\n",
    "def load_all_output_files(data_dir=\"../data\", weeks=None):\n",
    "    \"\"\"Load all output CSV files for specified weeks (default: all weeks 1-18)\"\"\"\n",
    "    if weeks is None:\n",
    "        weeks = list(range(1, 19))  # Weeks 1-18\n",
    "    \n",
    "    output_frames = []\n",
    "    for w in weeks:\n",
    "        fname = f\"{data_dir}/output_2023_w{w:02d}.csv\"\n",
    "        try:\n",
    "            df = pd.read_csv(fname)\n",
    "            df[\"week\"] = w\n",
    "            output_frames.append(df)\n",
    "            print(f\"  ✓ Loaded output_2023_w{w:02d}.csv: {len(df):,} rows\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  ⚠ Skipping missing file: {fname}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error loading {fname}: {e}\")\n",
    "    \n",
    "    if not output_frames:\n",
    "        raise ValueError(\"No output files were loaded!\")\n",
    "    \n",
    "    return pd.concat(output_frames, ignore_index=True)\n",
    "\n",
    "# Load all input data (pre-throw) - Using configured weeks\n",
    "print(\"\\nLoading INPUT data (pre-throw)...\")\n",
    "input_df = load_all_input_files(weeks=WEEKS_TO_PROCESS)\n",
    "print(f\"\\n✓ Total input data loaded: {len(input_df):,} rows\")\n",
    "print(f\"  Columns: {list(input_df.columns[:10])}... ({len(input_df.columns)} total)\")\n",
    "print(f\"  Weeks included: {sorted(input_df['week'].unique())}\")\n",
    "\n",
    "# Load all output data (post-throw) - Using configured weeks\n",
    "print(\"\\nLoading OUTPUT data (post-throw)...\")\n",
    "output_df = load_all_output_files(weeks=WEEKS_TO_PROCESS)\n",
    "print(f\"\\n✓ Total output data loaded: {len(output_df):,} rows\")\n",
    "print(f\"  Columns: {list(output_df.columns[:10])}... ({len(output_df.columns)} total)\")\n",
    "print(f\"  Weeks included: {sorted(output_df['week'].unique())}\")\n",
    "\n",
    "# Load supplementary data (play context)\n",
    "print(\"\\nLoading SUPPLEMENTARY data...\")\n",
    "supp_df = pd.read_csv(\"../data/Supplementary.csv\")\n",
    "print(f\"✓ Supplementary data loaded: {len(supp_df):,} rows\")\n",
    "print(f\"  Columns: {list(supp_df.columns[:10])}... ({len(supp_df.columns)} total)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Input data shape: {input_df.shape}\")\n",
    "print(f\"  Unique plays: {input_df[['game_id', 'play_id']].drop_duplicates().shape[0]:,}\")\n",
    "print(f\"  Weeks: {sorted(input_df['week'].unique())}\")\n",
    "print(f\"\\nOutput data shape: {output_df.shape}\")\n",
    "print(f\"  Unique plays: {output_df[['game_id', 'play_id']].drop_duplicates().shape[0]:,}\")\n",
    "print(f\"  Weeks: {sorted(output_df['week'].unique())}\")\n",
    "print(f\"\\nSupplementary data shape: {supp_df.shape}\")\n",
    "print(f\"  Unique plays: {supp_df[['game_id', 'play_id']].drop_duplicates().shape[0]:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore Data Structure\n",
    "\n",
    "Let's examine what plays we have and understand the data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total plays with targeted receivers: 819\n",
      "\n",
      "Sample targeted plays:\n",
      "         game_id  play_id  nfl_id        player_name\n",
      "208   2023090700      101   44930      Josh Reynolds\n",
      "618   2023090700      194   41325    Jerick McKinnon\n",
      "854   2023090700      219   53591          Noah Gray\n",
      "1381  2023090700      361   38696       Marvin Jones\n",
      "1632  2023090700      436   53541  Amon-Ra St. Brown\n",
      "1928  2023090700      461   44930      Josh Reynolds\n",
      "2191  2023090700      530   53541  Amon-Ra St. Brown\n",
      "2559  2023090700      621   53541  Amon-Ra St. Brown\n",
      "2876  2023090700      713   53591          Noah Gray\n",
      "3241  2023090700      736   46213      Justin Watson\n",
      "\n",
      "================================================================================\n",
      "FRAME COUNT ANALYSIS\n",
      "================================================================================\n",
      "Input frames per play:\n",
      "  Average: 348.9\n",
      "  Min: 81\n",
      "  Max: 888\n",
      "\n",
      "Output frames per play:\n",
      "  Average: 39.2\n",
      "  Min: 5\n",
      "  Max: 752\n",
      "\n",
      "================================================================================\n",
      "COMPLETION STATUS\n",
      "================================================================================\n",
      "pass_result\n",
      "C     12470\n",
      "I      5106\n",
      "IN      433\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Completion rate: 69.2%\n"
     ]
    }
   ],
   "source": [
    "# Find plays with targeted receivers\n",
    "targeted_plays = input_df[\n",
    "    input_df[\"player_role\"] == \"Targeted Receiver\"\n",
    "][[\"game_id\", \"play_id\", \"nfl_id\", \"player_name\"]].drop_duplicates()\n",
    "\n",
    "print(f\"Total plays with targeted receivers: {len(targeted_plays):,}\")\n",
    "print(f\"\\nSample targeted plays:\")\n",
    "print(targeted_plays.head(10))\n",
    "\n",
    "# Check frame counts\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"FRAME COUNT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count frames per play in input data\n",
    "input_frame_counts = input_df.groupby([\"game_id\", \"play_id\"]).size()\n",
    "print(f\"Input frames per play:\")\n",
    "print(f\"  Average: {input_frame_counts.mean():.1f}\")\n",
    "print(f\"  Min: {input_frame_counts.min()}\")\n",
    "print(f\"  Max: {input_frame_counts.max()}\")\n",
    "\n",
    "# Count frames per play in output data\n",
    "output_frame_counts = output_df.groupby([\"game_id\", \"play_id\"]).size()\n",
    "print(f\"\\nOutput frames per play:\")\n",
    "print(f\"  Average: {output_frame_counts.mean():.1f}\")\n",
    "print(f\"  Min: {output_frame_counts.min()}\")\n",
    "print(f\"  Max: {output_frame_counts.max()}\")\n",
    "\n",
    "# Check completion status\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETION STATUS\")\n",
    "print(\"=\"*80)\n",
    "if \"pass_result\" in supp_df.columns:\n",
    "    completion_counts = supp_df[\"pass_result\"].value_counts()\n",
    "    print(completion_counts)\n",
    "    print(f\"\\nCompletion rate: {(completion_counts.get('C', 0) / len(supp_df) * 100):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Route Dominance Scorer\n",
    "\n",
    "The RouteDominanceScorer combines input and output data, calculates motion features, and provides methods to compute dominance metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Route Dominance Scorer...\n",
      "This combines input and output data, estimates motion features, and prepares for metric calculation...\n",
      "✓ Route Dominance Scorer initialized\n",
      "  Combined frames: 317,802 rows\n",
      "  Unique plays: 819\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scorer\n",
    "print(\"Initializing Route Dominance Scorer...\")\n",
    "print(\"This combines input and output data, estimates motion features, and prepares for metric calculation...\")\n",
    "\n",
    "scorer = RouteDominanceScorer(input_df, output_df, supp_df)\n",
    "\n",
    "print(\"✓ Route Dominance Scorer initialized\")\n",
    "print(f\"  Combined frames: {len(scorer.all_frames_df):,} rows\")\n",
    "print(f\"  Unique plays: {scorer.all_frames_df[['game_id', 'play_id']].drop_duplicates().shape[0]:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Process Plays and Calculate Metrics\n",
    "\n",
    "For each play with a targeted receiver, we will:\n",
    "1. Calculate frame-by-frame dominance metrics for all frames in the play\n",
    "2. Add play context (formation, coverage, completion status)\n",
    "3. Add continuous frame numbering (starting from 1, varies by play)\n",
    "4. Add throw status (pre_throw vs after_throw) to distinguish frame types\n",
    "5. Calculate nearest defender coordinates for each frame\n",
    "6. Compute route-level dominance scores aggregated across all frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Function defined\n"
     ]
    }
   ],
   "source": [
    "# Function to create training DataFrame",
    "def create_training_dataframe(input_df, output_df, supp_df, scorer, weeks=None, max_plays=None):",
    "    \"\"\"",
    "    Create a training-ready DataFrame with all route dominance metrics",
    "    ",
    "    Args:",
    "        input_df: Input DataFrame (pre-throw data)",
    "        output_df: Output DataFrame (post-throw data)",
    "        supp_df: Supplementary DataFrame (play context)",
    "        scorer: Initialized RouteDominanceScorer",
    "        weeks: List of weeks to process (None = all weeks)",
    "        max_plays: Maximum number of plays to process (None = all plays)",
    "    ",
    "    Returns:",
    "        DataFrame with all metrics for model training",
    "    \"\"\"",
    "    print(\"=\"*80)",
    "    print(\"PROCESSING PLAYS\")",
    "    print(\"=\"*80)",
    "    ",
    "    # Get all unique plays with targeted receivers",
    "    # Include 'week' column for filtering (we added this during data loading)",
    "    targeted_plays = input_df[",
    "        input_df[\"player_role\"] == \"Targeted Receiver\"",
    "    ][[\"game_id\", \"play_id\", \"nfl_id\", \"player_name\", \"week\"]].drop_duplicates()",
    "    ",
    "    if weeks is not None:",
    "        # Filter by weeks if specified (using the week column we added during loading)",
    "        targeted_plays = targeted_plays[",
    "            targeted_plays[\"week\"].isin(weeks)",
    "        ]",
    "    ",
    "    if max_plays is not None:",
    "        targeted_plays = targeted_plays.head(max_plays)",
    "    ",
    "    # Remove 'week' column before processing (not needed in the loop)",
    "    targeted_plays = targeted_plays[[\"game_id\", \"play_id\", \"nfl_id\", \"player_name\"]]",
    "    ",
    "    print(f\"Processing {len(targeted_plays)} plays...\")",
    "    if len(targeted_plays) == 0:",
    "        print(\"⚠ WARNING: No plays found!\")",
    "        print(\"  Check your WEEKS_TO_PROCESS configuration.\")",
    "        if \"week\" in input_df.columns:",
    "            print(f\"  Available weeks in data: {sorted(input_df['week'].unique())}\")",
    "        else:",
    "            print(\"  ERROR: 'week' column not found in input_df!\")",
    "        return pd.DataFrame(), []",
    "    ",
    "    all_metrics = []",
    "    errors = []",
    "    ",
    "    for idx, row in tqdm(targeted_plays.iterrows(), total=len(targeted_plays), desc=\"Processing\"):",
    "        game_id = row[\"game_id\"]",
    "        play_id = row[\"play_id\"]",
    "        target_nfl_id = row[\"nfl_id\"]",
    "        target_name = row[\"player_name\"]",
    "        ",
    "        try:",
    "            # Calculate frame-by-frame dominance",
    "            frame_metrics = scorer.calculate_frame_dominance(game_id, play_id, target_nfl_id)",
    "            ",
    "            # Get play context from supplementary data",
    "            supp_row = supp_df[",
    "                (supp_df[\"game_id\"] == game_id) &",
    "                (supp_df[\"play_id\"] == play_id)",
    "            ]",
    "            ",
    "            if not supp_row.empty:",
    "                # Get completion status (1 = Complete, 0 = Incomplete)",
    "                pass_result = supp_row.iloc[0].get(\"pass_result\", \"UNKNOWN\")",
    "                is_complete = 1 if pass_result == \"C\" else 0",
    "                ",
    "                # Get formation and context info",
    "                offense_formation = supp_row.iloc[0].get(\"offense_formation\", \"UNKNOWN\")",
    "                receiver_alignment = supp_row.iloc[0].get(\"receiver_alignment\", \"UNKNOWN\")",
    "                coverage_type = supp_row.iloc[0].get(\"team_coverage_type\", \"UNKNOWN\")",
    "                down = supp_row.iloc[0].get(\"down\", np.nan)",
    "                yards_to_go = supp_row.iloc[0].get(\"yards_to_go\", np.nan)",
    "                pass_length = supp_row.iloc[0].get(\"pass_length\", np.nan)",
    "                route = supp_row.iloc[0].get(\"route_of_targeted_receiver\", \"UNKNOWN\")",
    "            else:",
    "                is_complete = np.nan",
    "                offense_formation = \"UNKNOWN\"",
    "                receiver_alignment = \"UNKNOWN\"",
    "                coverage_type = \"UNKNOWN\"",
    "                down = np.nan",
    "                yards_to_go = np.nan",
    "                pass_length = np.nan",
    "                route = \"UNKNOWN\"",
    "            ",
    "            # Add play-level context to each frame",
    "            frame_metrics[\"target_name\"] = target_name",
    "            frame_metrics[\"is_complete\"] = is_complete",
    "            frame_metrics[\"offense_formation\"] = offense_formation",
    "            frame_metrics[\"receiver_alignment\"] = receiver_alignment",
    "            frame_metrics[\"coverage_type\"] = coverage_type",
    "            frame_metrics[\"down\"] = down",
    "            frame_metrics[\"yards_to_go\"] = yards_to_go",
    "            frame_metrics[\"pass_length\"] = pass_length",
    "            ",
    "            # Add continuous frame number (varies by play - starts at 1, increments for each frame)",
    "            frame_metrics[\"continuous_frame\"] = range(1, len(frame_metrics) + 1)",
    "            ",
    "            # Add throw_status column (pre_throw for input, after_throw for output)",
    "            frame_metrics[\"throw_status\"] = frame_metrics[\"frame_type\"].map({",
    "                \"input\": \"pre_throw\",",
    "                \"output\": \"after_throw\"",
    "            })",
    "            ",
    "            # Get nearest defender coordinates for each frame",
    "            nearest_def_x = []",
    "            nearest_def_y = []",
    "            ",
    "            for _, frame_row in frame_metrics.iterrows():",
    "                frame_id = frame_row[\"frame_id\"]",
    "                frame_type = frame_row[\"frame_type\"]",
    "                ",
    "                # Get all players at this frame",
    "                play_frames = scorer.all_frames_df[",
    "                    (scorer.all_frames_df[\"game_id\"] == game_id) &",
    "                    (scorer.all_frames_df[\"play_id\"] == play_id) &",
    "                    (scorer.all_frames_df[\"frame_id\"] == frame_id) &",
    "                    (scorer.all_frames_df[\"frame_type\"] == frame_type)",
    "                ]",
    "                ",
    "                # Get defenders",
    "                defenders = play_frames[play_frames[\"player_side\"] == \"Defense\"]",
    "                ",
    "                if not defenders.empty and not np.isnan(frame_row[\"sep_nearest\"]) and frame_row[\"sep_nearest\"] < np.inf:",
    "                    # Get receiver position",
    "                    receiver_frame = play_frames[play_frames[\"nfl_id\"] == target_nfl_id]",
    "                    if not receiver_frame.empty:",
    "                        rec_x = receiver_frame.iloc[0][\"x_std\"]",
    "                        rec_y = receiver_frame.iloc[0][\"y_std\"]",
    "                        ",
    "                        # Calculate distances to find nearest defender",
    "                        def_dists = np.sqrt(",
    "                            (defenders[\"x_std\"] - rec_x)**2 +",
    "                            (defenders[\"y_std\"] - rec_y)**2",
    "                        )",
    "                        nearest_idx = def_dists.idxmin()",
    "                        nearest_def = defenders.loc[nearest_idx]",
    "                        nearest_def_x.append(nearest_def[\"x_std\"])",
    "                        nearest_def_y.append(nearest_def[\"y_std\"])",
    "                    else:",
    "                        nearest_def_x.append(np.nan)",
    "                        nearest_def_y.append(np.nan)",
    "                else:",
    "                    nearest_def_x.append(np.nan)",
    "                    nearest_def_y.append(np.nan)",
    "            ",
    "            frame_metrics[\"nearest_defender_x\"] = nearest_def_x",
    "            frame_metrics[\"nearest_defender_y\"] = nearest_def_y",
    "            ",
    "            # Calculate route-level dominance scores",
    "            route_avg = scorer.calculate_route_dominance(frame_metrics, method=\"average\")",
    "            route_weighted = scorer.calculate_route_dominance(frame_metrics, method=\"weighted_average\")",
    "            route_max = scorer.calculate_route_dominance(frame_metrics, method=\"max\")",
    "            route_min = scorer.calculate_route_dominance(frame_metrics, method=\"min\")",
    "            ",
    "            # Add route-level scores to each frame",
    "            frame_metrics[\"route_dominance_avg\"] = route_avg",
    "            frame_metrics[\"route_dominance_weighted\"] = route_weighted",
    "            frame_metrics[\"route_dominance_max\"] = route_max",
    "            frame_metrics[\"route_dominance_min\"] = route_min",
    "            ",
    "            all_metrics.append(frame_metrics)",
    "            ",
    "        except Exception as e:",
    "            errors.append((game_id, play_id, str(e)))",
    "            continue",
    "    ",
    "    if not all_metrics:",
    "        print(\"No metrics generated!\")",
    "        return pd.DataFrame(), errors",
    "    ",
    "    # Combine all frames",
    "    training_df = pd.concat(all_metrics, ignore_index=True)",
    "    ",
    "    print(f\"\\n✓ Processing complete!\")",
    "    print(f\"  Total rows: {len(training_df):,}\")",
    "    print(f\"  Total plays: {training_df[['game_id', 'play_id']].drop_duplicates().shape[0]:,}\")",
    "    print(f\"  Errors: {len(errors)}\")",
    "    ",
    "    return training_df, errors",
    "",
    "print(\"✓ Function defined\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Training DataFrame\n",
    "\n",
    "Now let's process all plays from the configured weeks and create the training DataFrame. \n",
    "\n",
    "**Configuration Options:**\n",
    "- **Weeks**: Set `WEEKS_TO_PROCESS` in the Configuration cell (Cell 3) to control which weeks to process\n",
    "- **Max Plays**: For faster testing, you can also limit with `max_plays` parameter below (e.g., `max_plays=100`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PROCESSING PLAYS\n",
      "================================================================================\n",
      "Processing 0 plays...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metrics generated!\n",
      "\n",
      "================================================================================\n",
      "FILTERING THROWAWAYS AND MISTHROWS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'game_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m MAX_MISS_DIST = \u001b[32m8\u001b[39m  \u001b[38;5;66;03m# yards - threshold for considering a pass a throwaway\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Get the last frame for each play (ball arrival frame)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m last_frames = \u001b[43mtraining_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgame_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplay_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.last().reset_index()\n\u001b[32m     20\u001b[39m throwaway_mask = last_frames[\u001b[33m\"\u001b[39m\u001b[33mdist_to_ball\u001b[39m\u001b[33m\"\u001b[39m] > MAX_MISS_DIST\n\u001b[32m     22\u001b[39m throwaway_plays = last_frames[throwaway_mask][[\u001b[33m\"\u001b[39m\u001b[33mgame_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mplay_id\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alexx\\Documents\\NFLDataBowl\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:9210\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9213\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9216\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alexx\\Documents\\NFLDataBowl\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1331\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1328\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alexx\\Documents\\NFLDataBowl\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'game_id'"
     ]
    }
   ],
   "source": [
    "# Create training DataFrame\n",
    "# Note: Weeks are controlled by WEEKS_TO_PROCESS in Configuration cell (Cell 3)\n",
    "# Set max_plays=None to process all plays, or set a number for faster testing\n",
    "training_df, errors = create_training_dataframe(\n",
    "    input_df, output_df, supp_df, scorer, \n",
    "    weeks=WEEKS_TO_PROCESS,  # Uses configuration from Cell 3\n",
    "    max_plays=None  # Process all plays (set to a number like 100 for faster testing)\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"FILTERING THROWAWAYS AND MISTHROWS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter out throwaways: plays where ball was nowhere near the target receiver\n",
    "# Use the distance to ball at the last frame (ball arrival) to determine throwaways\n",
    "MAX_MISS_DIST = 8  # yards - threshold for considering a pass a throwaway\n",
    "\n",
    "# Get the last frame for each play (ball arrival frame)\n",
    "last_frames = training_df.groupby([\"game_id\", \"play_id\"]).last().reset_index()\n",
    "throwaway_mask = last_frames[\"dist_to_ball\"] > MAX_MISS_DIST\n",
    "\n",
    "throwaway_plays = last_frames[throwaway_mask][[\"game_id\", \"play_id\"]]\n",
    "print(f\"Found {len(throwaway_plays)} plays with ball > {MAX_MISS_DIST} yards from receiver\")\n",
    "print(f\"Percentage of plays: {100 * len(throwaway_plays) / len(last_frames):.1f}%\")\n",
    "\n",
    "# Filter out throwaway plays from training DataFrame\n",
    "if len(throwaway_plays) > 0:\n",
    "    training_df = training_df[\n",
    "        ~training_df.set_index([\"game_id\", \"play_id\"]).index.isin(\n",
    "            throwaway_plays.set_index([\"game_id\", \"play_id\"]).index\n",
    "        )\n",
    "    ].reset_index(drop=True)\n",
    "    print(f\"\\n✓ Filtered out {len(throwaway_plays)} throwaway plays\")\n",
    "    print(f\"  Remaining plays: {training_df[['game_id', 'play_id']].drop_duplicates().shape[0]:,}\")\n",
    "    print(f\"  Remaining frames: {len(training_df):,}\")\n",
    "else:\n",
    "    print(\"\\n✓ No throwaway plays found (all passes were within threshold)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Explore the Training DataFrame\n",
    "\n",
    "Let's examine what we've created and verify the structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING DATAFRAME SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Shape: {training_df.shape}\")\n",
    "print(f\"\\nColumns ({len(training_df.columns)} total):\")\n",
    "for i, col in enumerate(training_df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE DATA\")\n",
    "print(\"=\"*80)\n",
    "display_cols = [\n",
    "    \"game_id\", \"play_id\", \"continuous_frame\", \"frame_type\", \"throw_status\",\n",
    "    \"dominance_score\", \"is_complete\", \"sep_nearest\", \"receiver_speed\",\n",
    "    \"leverage_angle\", \"nearest_defender_x\", \"nearest_defender_y\"\n",
    "]\n",
    "print(training_df[display_cols].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify frame counts per play\n",
    "print(\"=\"*80)\n",
    "print(\"FRAME COUNT VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "frame_counts = training_df.groupby([\"game_id\", \"play_id\"]).size()\n",
    "print(f\"Average frames per play: {frame_counts.mean():.1f}\")\n",
    "print(f\"Min frames: {frame_counts.min()}, Max frames: {frame_counts.max()}\")\n",
    "\n",
    "# Check throw status distribution\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"THROW STATUS DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "print(training_df[\"throw_status\"].value_counts())\n",
    "\n",
    "# Check completion rate\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETION STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Completion rate: {training_df['is_complete'].mean():.2%}\")\n",
    "print(f\"Complete plays: {training_df['is_complete'].sum():,}\")\n",
    "print(f\"Incomplete plays: {(~training_df['is_complete'].astype(bool)).sum():,}\")\n",
    "\n",
    "# Sample play breakdown\n",
    "sample_play = training_df[\n",
    "    (training_df[\"game_id\"] == training_df[\"game_id\"].iloc[0]) &\n",
    "    (training_df[\"play_id\"] == training_df[\"play_id\"].iloc[0])\n",
    "]\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE PLAY BREAKDOWN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Game ID: {sample_play['game_id'].iloc[0]}\")\n",
    "print(f\"Play ID: {sample_play['play_id'].iloc[0]}\")\n",
    "print(f\"Target Receiver: {sample_play['target_name'].iloc[0]}\")\n",
    "print(f\"Total frames: {len(sample_play)}\")\n",
    "print(f\"Pre-throw frames: {len(sample_play[sample_play['throw_status'] == 'pre_throw'])}\")\n",
    "print(f\"After-throw frames: {len(sample_play[sample_play['throw_status'] == 'after_throw'])}\")\n",
    "print(f\"Completion: {'Complete' if sample_play['is_complete'].iloc[0] == 1 else 'Incomplete'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Statistical Summary\n",
    "\n",
    "Let's look at the distribution of key metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"METRIC STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metric_cols = [\n",
    "    \"dominance_score\", \"sep_nearest\", \"receiver_speed\", \"receiver_accel\",\n",
    "    \"leverage_angle\", \"time_advantage\", \"num_def_within_3\"\n",
    "]\n",
    "\n",
    "print(training_df[metric_cols].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.5: EDA Visualizations\n",
    "\n",
    "Let's create visualizations similar to the preprocessing notebook to understand the data distribution and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get route-level data (one row per play) for EDA\n",
    "route_level_df = training_df.groupby([\"game_id\", \"play_id\"]).agg({\n",
    "    \"dist_to_ball\": \"last\",  # Distance at ball arrival\n",
    "    \"sep_nearest\": \"last\",    # Separation at ball arrival\n",
    "    \"is_complete\": \"first\",\n",
    "    \"route\": \"first\",\n",
    "    \"dominance_score\": \"mean\",\n",
    "    \"receiver_speed\": \"mean\",\n",
    "    \"leverage_angle\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"Route-level data shape: {route_level_df.shape}\")\n",
    "print(f\"Unique routes: {route_level_df['route'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 1: Distance to Ball Distribution - Caught vs Not Caught\n",
    "\n",
    "Compare the distribution of receiver-to-ball distance for completed vs incomplete passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Distance to ball distribution - caught vs not caught\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharex=True, sharey=True)\n",
    "\n",
    "caught_mask = route_level_df[\"is_complete\"] == 1\n",
    "not_caught_mask = route_level_df[\"is_complete\"] == 0\n",
    "\n",
    "sns.histplot(\n",
    "    route_level_df.loc[caught_mask, \"dist_to_ball\"],\n",
    "    bins=50,\n",
    "    stat=\"density\",\n",
    "    ax=axes[0],\n",
    "    color=\"green\",\n",
    "    alpha=0.7\n",
    ")\n",
    "axes[0].set_xlim(0, 40)\n",
    "axes[0].set_title(\"Caught passes: receiver-to-ball distance\")\n",
    "axes[0].set_xlabel(\"Distance (yards)\")\n",
    "axes[0].axvline(route_level_df.loc[caught_mask, \"dist_to_ball\"].mean(), \n",
    "                color=\"darkgreen\", linestyle=\"--\", label=f\"Mean: {route_level_df.loc[caught_mask, 'dist_to_ball'].mean():.2f} yds\")\n",
    "axes[0].legend()\n",
    "\n",
    "sns.histplot(\n",
    "    route_level_df.loc[not_caught_mask, \"dist_to_ball\"],\n",
    "    bins=50,\n",
    "    stat=\"density\",\n",
    "    ax=axes[1],\n",
    "    color=\"red\",\n",
    "    alpha=0.7\n",
    ")\n",
    "axes[1].set_xlim(0, 40)\n",
    "axes[1].set_title(\"Not caught passes: receiver-to-ball distance\")\n",
    "axes[1].set_xlabel(\"Distance (yards)\")\n",
    "axes[1].axvline(route_level_df.loc[not_caught_mask, \"dist_to_ball\"].mean(), \n",
    "                color=\"darkred\", linestyle=\"--\", label=f\"Mean: {route_level_df.loc[not_caught_mask, 'dist_to_ball'].mean():.2f} yds\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean distance (caught): {route_level_df.loc[caught_mask, 'dist_to_ball'].mean():.2f} yards\")\n",
    "print(f\"Mean distance (not caught): {route_level_df.loc[not_caught_mask, 'dist_to_ball'].mean():.2f} yards\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 2: Overall Distance to Ball Distribution\n",
    "\n",
    "Distribution of receiver-to-ball distance for all passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Overall distance to ball distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(route_level_df[\"dist_to_ball\"], bins=50, stat=\"density\", kde=True)\n",
    "plt.axvline(route_level_df[\"dist_to_ball\"].mean(), color=\"red\", linestyle=\"--\", \n",
    "            label=f\"Mean: {route_level_df['dist_to_ball'].mean():.2f} yds\")\n",
    "plt.axvline(MAX_MISS_DIST, color=\"orange\", linestyle=\"--\", \n",
    "            label=f\"Throwaway threshold: {MAX_MISS_DIST} yds\")\n",
    "plt.xlim(0, 40)\n",
    "plt.title(\"Distribution of receiver to ball distance at arrival\")\n",
    "plt.xlabel(\"Distance (yards)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Statistics:\")\n",
    "print(route_level_df[\"dist_to_ball\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 3: Separation by Catch Outcome\n",
    "\n",
    "Compare nearest defender separation for completed vs incomplete passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Separation by catch outcome\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(\n",
    "    data=route_level_df, \n",
    "    x=\"sep_nearest\", \n",
    "    hue=\"is_complete\", \n",
    "    bins=30, \n",
    "    stat=\"density\", \n",
    "    kde=True,\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.title(\"Nearest defender separation at arrival vs. catch outcome\")\n",
    "plt.xlabel(\"Separation (yards)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"Caught\", labels=[\"No\", \"Yes\"])\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean separation (caught): {route_level_df.loc[caught_mask, 'sep_nearest'].mean():.2f} yards\")\n",
    "print(f\"Mean separation (not caught): {route_level_df.loc[not_caught_mask, 'sep_nearest'].mean():.2f} yards\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 4: Ball Distance vs Separation\n",
    "\n",
    "Scatter plot showing the relationship between ball distance and defender separation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4: Ball distance vs separation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=route_level_df, \n",
    "    x=\"sep_nearest\", \n",
    "    y=\"dist_to_ball\", \n",
    "    hue=\"is_complete\", \n",
    "    alpha=0.5,\n",
    "    s=50\n",
    ")\n",
    "plt.title(\"Ball distance vs. separation\")\n",
    "plt.xlabel(\"Separation from nearest defender (yards)\")\n",
    "plt.ylabel(\"Distance to ball (yards)\")\n",
    "plt.legend(title=\"Caught\", labels=[\"No\", \"Yes\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 5: Catch Rate by Route Type\n",
    "\n",
    "Bar plot showing catch rate for different route types (only routes with sufficient samples).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5: Catch rate by route type\n",
    "min_samples = 10  # Minimum number of targets for a route to be included\n",
    "\n",
    "route_stats = route_level_df.groupby(\"route\").agg({\n",
    "    \"is_complete\": [\"mean\", \"count\"]\n",
    "}).reset_index()\n",
    "route_stats.columns = [\"route\", \"mean\", \"count\"]\n",
    "route_stats = route_stats[route_stats[\"count\"] >= min_samples].sort_values(\"mean\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=route_stats.head(20), x=\"mean\", y=\"route\", palette=\"viridis\")\n",
    "plt.title(f\"Catch rate by route (>= {min_samples} targets)\")\n",
    "plt.xlabel(\"Catch rate\")\n",
    "plt.ylabel(\"Route type\")\n",
    "plt.xlim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop routes by catch rate:\")\n",
    "print(route_stats.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 6: Dominance Score Distribution\n",
    "\n",
    "Compare dominance scores for completed vs incomplete passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 6: Dominance score distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(\n",
    "    data=route_level_df, \n",
    "    x=\"dominance_score\", \n",
    "    hue=\"is_complete\", \n",
    "    bins=30, \n",
    "    stat=\"density\", \n",
    "    kde=True,\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.title(\"Route dominance score vs. catch outcome\")\n",
    "plt.xlabel(\"Dominance Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"Caught\", labels=[\"No\", \"Yes\"])\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean dominance (caught): {route_level_df.loc[caught_mask, 'dominance_score'].mean():.3f}\")\n",
    "print(f\"Mean dominance (not caught): {route_level_df.loc[not_caught_mask, 'dominance_score'].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Training DataFrame\n",
    "\n",
    "Save the DataFrame to CSV for use in model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_file = \"route_dominance_training_data.csv\"\n",
    "print(f\"Saving training DataFrame to {output_file}...\")\n",
    "training_df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Saved {len(training_df):,} rows to {output_file}\")\n",
    "print(f\"  File size: {pd.io.common.file_size(output_file)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Interactive Visualization\n",
    "\n",
    "Use the interactive visualizer to explore plays frame-by-frame. Navigate with arrow keys:\n",
    "- **Left Arrow**: Previous frame\n",
    "- **Right Arrow**: Next frame\n",
    "- **Up Arrow**: Jump to first frame\n",
    "- **Down Arrow**: Jump to last frame\n",
    "- **'q' or Escape**: Quit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example play to visualize\n",
    "example_game_id = 2023090700\n",
    "example_play_id = 101\n",
    "\n",
    "# Get targeted receiver for this play\n",
    "target_info = input_df[\n",
    "    (input_df[\"game_id\"] == example_game_id) &\n",
    "    (input_df[\"play_id\"] == example_play_id) &\n",
    "    (input_df[\"player_role\"] == \"Targeted Receiver\")\n",
    "]\n",
    "\n",
    "if not target_info.empty:\n",
    "    target_nfl_id = target_info[\"nfl_id\"].iloc[0]\n",
    "    target_name = target_info[\"player_name\"].iloc[0]\n",
    "    \n",
    "    print(f\"Creating interactive viewer for:\")\n",
    "    print(f\"  Game ID: {example_game_id}\")\n",
    "    print(f\"  Play ID: {example_play_id}\")\n",
    "    print(f\"  Targeted Receiver: {target_name} (NFL ID: {target_nfl_id})\")\n",
    "    print(\"\\nControls:\")\n",
    "    print(\"  Left Arrow  : Previous frame\")\n",
    "    print(\"  Right Arrow : Next frame\")\n",
    "    print(\"  Up Arrow    : Jump to first frame\")\n",
    "    print(\"  Down Arrow  : Jump to last frame\")\n",
    "    print(\"  'q' or Esc  : Quit\")\n",
    "    print(\"\\nClick on the plot window and use arrow keys to navigate!\")\n",
    "    \n",
    "    # Create interactive viewer\n",
    "    viewer = InteractiveRouteDominanceViewer(scorer, example_game_id, example_play_id, target_nfl_id)\n",
    "else:\n",
    "    print(f\"Targeted receiver not found for play {example_game_id}-{example_play_id}\")\n",
    "    print(\"\\nAvailable plays:\")\n",
    "    print(targeted_plays.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Compare Completed vs Incomplete Plays\n",
    "\n",
    "Let's analyze differences between completed and incomplete passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare completed vs incomplete plays\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETED VS INCOMPLETE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define metrics to compare\n",
    "metric_cols = [\n",
    "    \"dominance_score\", \"route_dominance_weighted\", \"sep_nearest\",\n",
    "    \"receiver_speed\", \"leverage_angle\", \"time_advantage\"\n",
    "]\n",
    "\n",
    "# Calculate route-level averages for each play\n",
    "route_level = training_df.groupby([\"game_id\", \"play_id\", \"is_complete\"]).agg({\n",
    "    \"dominance_score\": \"mean\",\n",
    "    \"route_dominance_weighted\": \"first\",\n",
    "    \"sep_nearest\": \"mean\",\n",
    "    \"receiver_speed\": \"mean\",\n",
    "    \"leverage_angle\": \"mean\",\n",
    "    \"time_advantage\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "complete_stats = route_level[route_level[\"is_complete\"] == 1][metric_cols].mean()\n",
    "incomplete_stats = route_level[route_level[\"is_complete\"] == 0][metric_cols].mean()\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Completed\": complete_stats,\n",
    "    \"Incomplete\": incomplete_stats,\n",
    "    \"Difference\": complete_stats - incomplete_stats\n",
    "})\n",
    "\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now have a comprehensive training DataFrame with:\n",
    "\n",
    "✅ **Continuous frame numbering** - Each play has variable numbers of frames (pre-throw + post-throw), numbered sequentially starting from 1  \n",
    "✅ **Throw status** column - Distinguishes pre-throw vs after-throw frames  \n",
    "✅ **Nearest defender coordinates** - X, Y positions of closest defender at each frame  \n",
    "✅ **Completion label** - Binary target variable (1 = Complete, 0 = Incomplete)  \n",
    "✅ **All dominance metrics** - Separation, speed, acceleration, leverage angle, time advantage, etc.  \n",
    "✅ **Route-level scores** - Aggregated scores (average, weighted, max, min) across all frames  \n",
    "✅ **Play context** - Formation, coverage, down, distance, route type  \n",
    "✅ **All weeks processed** - Data from weeks 1-18 included  \n",
    "\n",
    "The DataFrame is saved as `route_dominance_training_data.csv` and ready for model training!\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Feature Engineering**: Create additional features from existing metrics\n",
    "2. **Model Training**: Train LSTM, Transformer, or other sequential models on the frame sequences\n",
    "3. **Validation**: Split data and evaluate model performance\n",
    "4. **Analysis**: Explore which metrics are most predictive of completion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}